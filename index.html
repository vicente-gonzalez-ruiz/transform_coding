<!DOCTYPE html> 
<html lang="en-US" xml:lang="en-US" > 
<head> <title>Transform Coding</title> 
<meta  charset="utf-8" /> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" /> 
<link rel="stylesheet" type="text/css" href="index.css" /> 
<meta name="src" content="index.tex" /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script type="text/javascript" async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>  
</head><body 
>
   <div class="maketitle">
                                                                  

                                                                  
                                                                  

                                                                  

<h2 class="titleHead">Transform Coding</h2>
 <div class="author" ><a 
href="https://cms.ual.es/UAL/personas/persona.htm?id=515256515553484875" ><span 
class="ecrm-1200">Vicente Gonz</span><span 
class="ecrm-1200">á</span><span 
class="ecrm-1200">lez Ruiz</span></a> <span 
class="ecrm-1200">- </span><a 
href="https://cms.ual.es/UAL/universidad/departamentos/informatica/index.htm" ><span 
class="ecrm-1200">Depto Inform</span><span 
class="ecrm-1200">á</span><span 
class="ecrm-1200">tica</span></a> <span 
class="ecrm-1200">- </span><a 
href="https://www.ual.es" ><span 
class="ecrm-1200">UAL</span></a></div><br />
<div class="date" ><span 
class="ecrm-1200">May 28, 2022</span></div>
   </div>
   <h3 class="likesectionHead"><a 
 id="x1-1000"></a>Contents</h3>
   <div class="tableofcontents">
    <span class="sectionToc" >1 <a 
href="#x1-20001" id="QQ2-1-2">Information concentration</a></span>
<br />    <span class="sectionToc" >2 <a 
href="#x1-30002" id="QQ2-1-3">Matrix form of the transform</a></span>
<br />    <span class="sectionToc" >3 <a 
href="#x1-40003" id="QQ2-1-4">Transform coding gain</a></span>
<br />     <span class="subsectionToc" >3.1 <a 
href="#x1-50003.1" id="QQ2-1-5">Block-based transform coding</a></span>
<br />    <span class="sectionToc" >4 <a 
href="#x1-60004" id="QQ2-1-6">Resources</a></span>
<br />    <span class="sectionToc" ><a 
href="#Q1-1-7">References</a></span>
   </div>
<!--l. 7--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-20001"></a>Information concentration</h3>
<!--l. 11--><p class="noindent" ><a 
href="https://web.stanford.edu/class/ee398a/handouts/lectures/07-TransformCoding.pdf" >Transform coding</a> can exploit <a 
href="https://en.wikipedia.org/wiki/Correlation_and_dependence" >correlation</a> in <a 
href="https://en.wikipedia.org/wiki/Signal" >signals</a> to concentrate its
<a 
href="https://en.wikipedia.org/wiki/Information" >information</a><span class="footnote-mark"><a 
href="#fn1x0" id="fn1x0-bk"><sup class="textsuperscript">1</sup></a></span><a 
 id="x1-2001f1"></a>
in a subset of transformed elements called <span 
class="ecti-1000">coeﬃcients</span>, by decorrelating the input
samples <span class="cite">[<a 
href="#Xsayood2017introduction">1</a>]</span>. Normally, after the transformation, quantization of the signal is more
eﬀective<span class="footnote-mark"><a 
href="#fn2x0" id="fn2x0-bk"><sup class="textsuperscript">2</sup></a></span><a 
 id="x1-2002f2"></a>
when the energy of the signal is accumulated in an small number of coeﬃcients
because we can dedicate more bits to encode the more energetic ones.
                                                                  

                                                                  
</p><!--l. 29--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-30002"></a>Matrix form of the transform</h3>
<!--l. 32--><p class="noindent" >All linear<span class="footnote-mark"><a 
href="#fn3x0" id="fn3x0-bk"><sup class="textsuperscript">3</sup></a></span><a 
 id="x1-3001f3"></a>
transforms can be described as a <a 
href="https://en.wikipedia.org/wiki/Matrix_multiplication" >matrix-vector product</a> <span class="cite">[<a 
href="#Xstrang4linear">2</a>]</span> \begin {equation}  \mathbf {y} = \mathbf {K}\mathbf {x}, \label {eq:forward_transform_matrix_form}  \end {equation}
where \(\mathbf {x}\) is the input signal, \(\mathbf {K}\) is the analysis transform matrix, and \(\mathbf {y}\) is the output
decomposition. The coeﬃcients are found by \begin {equation}  {\mathbf {y}}_i = \langle {\mathbf {K}}_i, {\mathbf {x}}_i\rangle ,  \end {equation}
where \({\mathbf {K}}_i\) is the \(i\)-th row of \(\mathbf {K}\), and \(\langle \cdot ,\cdot \rangle \) denotes the <a 
href="https://mathworld.wolfram.com/InnerProduct.html" >inner product</a>. This basically means that \({\mathbf {y}}_i\)
is proportional to the <a 
href="https://en.wikipedia.org/wiki/Similarity_(geometry)" >similarity</a> between the input signal \(\mathbf {x}\) and the <a 
href="https://en.wikipedia.org/wiki/Finite_impulse_response" >taps</a> of the <a 
href="https://en.wikipedia.org/wiki/Digital_filter" >ﬁlter</a>
\({\mathbf {K}}_i\).<span class="footnote-mark"><a 
href="#fn4x0" id="fn4x0-bk"><sup class="textsuperscript">4</sup></a></span><a 
 id="x1-3002f4"></a> The
inverse (synthesis) transform is computed by \begin {equation}  \mathbf {x} = {\mathbf {K}}^{-1}\mathbf {y}, \label {eq:backward_transform_matrix_form}  \end {equation}
where \({\mathbf {K}}^{-1}\) denotes to the inverse matrix of \(\mathbf {K}\). When \(\mathbf K\) is orthonormal, it holds that
\begin {equation}  \mathbf {K}={\mathbf {K}}^{-1}={\mathbf {K}}^{\text T}, \label {eq:orthogonal_matrix}  \end {equation}
where \({\mathbf {K}}^{\text T}\) represents the transpose matrix of \(\mathbf {K}\). Without considering scale factors, Eq. <span 
class="ecbx-1000">??</span>
is also true for all <a 
href="https://en.wikipedia.org/wiki/Orthogonality" >orthogonal</a> transforms. Orthogonal and orthonormal transforms
satisfy that \begin {equation}  \langle {\mathbf {K}}_i, {\mathbf {K}}_j\rangle = 0, \forall i\neq j.  \end {equation}
</p><!--l. 80--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-40003"></a>Transform coding gain</h3>
<!--l. 83--><p class="noindent" >Transforms are used in signal coding to provide relative (between subbands) energy
compaction. The capatility of a transform to achieve this eﬀect can be estimated by
the so called <span 
class="ecti-1000">transform coding gain</span> <span class="cite">[<a 
href="#Xvetterli1995wavelets">3</a>, <a 
href="#Xsayood2017introduction">1</a>]</span> deﬁned by \begin {equation}  G = \frac {\frac {1}{N}\sum _{n=1}^N{\sigma _n^2}}{(\prod _{n=1}^N\sigma _n^2)^{\frac {1}{N}}},  \end {equation}
where \(N\) is the number of coeﬃcients in a block (in our case, the number of coeﬃcients
in a transformed pixel, i.e., \(N=3\)), and \(\sigma _n^2\) is the variance of the \(n\)-th coeﬃcient in the block.
As it can be seen, \(G\) is the ratio of the arithmetic mean of the variances of the
transform coeﬃcients to their geometric mean. Notice that \(G\) is computed
inside of a block (a pixel in the case of a color transform), not among blocks
(pixels).
</p><!--l. 100--><p class="noindent" >
</p>
   <h4 class="subsectionHead"><span class="titlemark">3.1   </span> <a 
 id="x1-50003.1"></a>Block-based transform coding</h4>
<!--l. 103--><p class="noindent" >Some transforms, such as the DCT are applied by 2D blocks which (for example, of \(8\times 8\)
pixels). This a direct consequence of that, usually, the transform losses compaction
eﬃciency when the block size is increased (although this depends on the signal
characteristics). When the coeﬃcients of several blocks are considered together,
they form a <a 
href="https://en.wikipedia.org/wiki/Sub-band_coding" >subband</a>, and the collection of subbands, a <a 
href="https://en.wikipedia.org/wiki/Discrete_wavelet_transform" >decomposition</a> <span class="cite">[<a 
href="#Xvetterli2014foundations">4</a>]</span>,
and the <a 
href="https://en.wikipedia.org/wiki/Array_data_structure#Element_identifier_and_addressing_formulas" >index</a> of the subband is related to the <a 
href="https://en.wikipedia.org/wiki/Frequency" >frequency</a> of the signal. For
example, in the case of the <a 
href="https://en.wikipedia.org/wiki/Digital_image" >images</a>, the position of the <a 
href="https://en.wikipedia.org/wiki/Coefficient" >coeﬃcients</a> in the
subbands is related to <a 
href="https://github.com/Sistemas-Multimedia/Sistemas-Multimedia.github.io/blob/master/milestones/07-DCT/block_DCT_compression.ipynb" >the spatial area where the corresponding pixels are
found</a>.
                                                                  

                                                                  
</p><!--l. 126--><p class="noindent" >
</p>
   <h3 class="sectionHead"><span class="titlemark">4   </span> <a 
 id="x1-60004"></a>Resources</h3>
   <div class="thebibliography">
   <p class="bibitem" ><span class="biblabel">
 [1]<span class="bibsp">   </span></span><a 
 id="Xsayood2017introduction"></a>K. Sayood.   <a 
href="http://rahilshaikh.weebly.com/uploads/1/1/6/3/11635894/data_compression.pdf" ><span 
class="ecti-1000">Introduction to Data Compression</span></a>.   Morgan  Kaufmann,
   2017.
   </p>
   <p class="bibitem" ><span class="biblabel">
 [2]<span class="bibsp">   </span></span><a 
 id="Xstrang4linear"></a>G. Strang. <a 
href="https://ia802906.us.archive.org/18/items/StrangG.LinearAlgebraAndItsApplications45881001/%5BStrang_G.%5D_Linear_algebra_and_its_applications%284%29%5B5881001%5D.pdf" ><span 
class="ecti-1000">Linear Algebra and Its Applications</span></a>. Belmont, CA: Thomson,
   Brooks/Cole, 2006.
   </p>
   <p class="bibitem" ><span class="biblabel">
 [3]<span class="bibsp">   </span></span><a 
 id="Xvetterli1995wavelets"></a>M. Vetterli  and  J. Kovačević.     <a 
href="http://waveletsandsubbandcoding.org/Repository/VetterliKovacevic95_Manuscript.pdf" ><span 
class="ecti-1000">Wavelets  and  Subband  Coding</span></a>.
   Prentice-hall, 1995.
   </p>
   <p class="bibitem" ><span class="biblabel">
 [4]<span class="bibsp">   </span></span><a 
 id="Xvetterli2014foundations"></a>M. Vetterli, J. Kovačević, and V.K. Goyal.  <a 
href="http://www.fourierandwavelets.org/FSP_v1.1_2014.pdf" ><span 
class="ecti-1000">Foundations of Signal</span>
   <span 
class="ecti-1000">Processing</span></a>. Cambridge University Press, 2014.
</p>
   </div>
<a 
 id="Q1-1-7"></a>
   <div class="footnotes"><!--l. 18--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn1x0-bk" id="fn1x0"><sup class="textsuperscript">1</sup></a></span><span 
class="ecrm-0800">That can be estimated through the </span><a 
href="https://en.wikipedia.org/wiki/Variance" ><span 
class="ecrm-0800">variance</span></a> <span 
class="ecrm-0800">or the </span><a 
href="https://en.wikipedia.org/wiki/Entropy" ><span 
class="ecrm-0800">entropy</span></a></p>
<!--l. 23--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn2x0-bk" id="fn2x0"><sup class="textsuperscript">2</sup></a></span><span 
class="ecrm-0800">for the same bit-rate, the lossy compression ratios are higher.</span></p>
<!--l. 33--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn3x0-bk" id="fn3x0"><sup class="textsuperscript">3</sup></a></span><span 
class="ecrm-0800">Non-linear transform are also possible, but their mathematical treatment is diﬀerent.</span></p>
<!--l. 57--><p class="indent" >     <span class="footnote-mark"><a 
href="#fn4x0-bk" id="fn4x0"><sup class="textsuperscript">4</sup></a></span><span 
class="ecrm-0800">These </span><a 
href="https://cseweb.ucsd.edu/classes/fa17/cse166-a/lec13.pdf" ><span 
class="ecrm-0800">slides</span></a> <span 
class="ecrm-0800">can help you with this key idea.</span></p>                                                    </div>
 
</body> 
</html>
                                                                  


